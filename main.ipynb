{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9833483,"sourceType":"datasetVersion","datasetId":6031466},{"sourceId":9835989,"sourceType":"datasetVersion","datasetId":6033406},{"sourceId":9918067,"sourceType":"datasetVersion","datasetId":6032826},{"sourceId":9918073,"sourceType":"datasetVersion","datasetId":6092588}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install elasticdeform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:02:56.3015Z","iopub.execute_input":"2024-11-16T10:02:56.302518Z","iopub.status.idle":"2024-11-16T10:03:07.970637Z","shell.execute_reply.started":"2024-11-16T10:02:56.302469Z","shell.execute_reply":"2024-11-16T10:03:07.969482Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport random\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import nn\nimport csv\n\n# from torchvision.transforms.v2 import GaussianNoise\n# from torchvision import transforms\n\nfrom torchvision.ops import sigmoid_focal_loss\n\n# from medpy.io import load\nimport pickle\n\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.transforms import v2\nimport torchvision.transforms.v2.functional as Fv2\n\nimport elasticdeform\nfrom torch.utils.data import ConcatDataset\n\nimport sys\nsys.path.insert(1, '/kaggle/input/extra-code/extras')\nfrom extra import *\n\n\ntrain_log_path = 'new_train_log'\nos.makedirs(train_log_path,exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:07.972655Z","iopub.execute_input":"2024-11-16T10:03:07.972998Z","iopub.status.idle":"2024-11-16T10:03:10.718449Z","shell.execute_reply.started":"2024-11-16T10:03:07.972965Z","shell.execute_reply":"2024-11-16T10:03:10.717526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"ROOT_PATH = \"/kaggle/input/brats2013-img-data-normalizedind-256-bin/brats2013_img_data_normalizedIND_256_bin\"\n# ROOT_PATH = \"/kaggle/input/brats2013-img-data-normalizedind-256-bin-all/brats2013_img_data_normalizedIND_256_bin_all\"\n\nclass Brats2013(Dataset):\n    def __init__(self, split_name, transform=None, root_path=ROOT_PATH):\n        self.root_path = root_path \n        self.split_name = split_name\n        self.data_paths = os.listdir(os.path.join(root_path, split_name))\n        self.transform = transform\n        \n    def load_data(self, path):\n        path = os.path.join(self.root_path, self.split_name, path)\n        with open(path, 'rb') as f:\n            data = pickle.load(f)\n        return data\n\n    def transform_images(self, img, mask):\n        elastic_5 = v2.ElasticTransform(alpha=5.0,sigma=5.0)\n        elastic_10  = v2.ElasticTransform(alpha=50.0,sigma=50.0)\n\n        if 0 in [img[0].max(), img[1].max(), img[2].max(), img[3].max()]:\n            return img, mask\n        \n        if 'h_flip' in self.transform:\n            img = Fv2.horizontal_flip(img) \n            mask = Fv2.horizontal_flip(mask) \n        if 'v_flip' in self.transform:\n            img = Fv2.vertical_flip(img) \n            mask = Fv2.vertical_flip(mask) \n        if 'rotate' in self.transform:\n            deg = np.random.randint(-30,30)\n            img = Fv2.rotate(img, deg) \n            mask = Fv2.rotate(mask, deg) \n        if 'crop' in self.transform:\n            img = Fv2.resize(img[:, 30:227, 30:227], (256, 256)) \n            mask = Fv2.resize(mask[:, 30:227, 30:227], (256, 256)) \n        if 'elastic_5' in self.transform:\n            img, mask = img.numpy(), mask.squeeze().numpy()\n            t_test_img = elasticdeform.deform_random_grid([*img, mask], sigma=5, points=3, mode='constant', order=[1,1,1,1,0])\n            \n            img, mask = torch.tensor(np.array(t_test_img[:4]), dtype=torch.float32), torch.tensor(np.array(t_test_img[4]), dtype=torch.uint8).unsqueeze(0)\n        \n        if 'brightness' in self.transform:\n            X_new = np.zeros(img.shape)\n            for c in range(img.shape[0]):\n                im = img[c,:,:]        \n                gain, gamma = (1.2 - 0.8) * np.random.random_sample(2,) + 0.8\n                im_new = np.sign(im)*gain*(np.abs(im)**gamma)\n                X_new[c,:,:] = im_new\n            img = torch.tensor(X_new/X_new.max(), dtype=torch.float32)\n            \n        \n        return img, mask\n        \n        \n    def __len__(self):\n        return len(self.data_paths)\n\n    def __getitem__(self, index):\n        data = self.load_data(self.data_paths[index])\n        \n        img, mask = data[:, :, :4], data[:, :, 4:]\n        img, mask = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1), torch.tensor(mask, dtype=torch.uint8).permute(2, 0, 1)\n        \n        if self.transform != None:\n            img, mask = self.transform_images(img, mask)\n        \n        return img, mask.squeeze()\n            \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:10.719986Z","iopub.execute_input":"2024-11-16T10:03:10.72072Z","iopub.status.idle":"2024-11-16T10:03:10.74557Z","shell.execute_reply.started":"2024-11-16T10:03:10.720676Z","shell.execute_reply":"2024-11-16T10:03:10.744531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transforms =[['h_flip'], ['v_flip'], ['rotate'], ['crop'], ['elastic_5'], ['brightness'], ['rotate', 'crop', 'elastic_5', 'brightness']]\nt_dataset = Brats2013('train', transforms[5])\nv_dataset = Brats2013('val')\ntest_dataset = Brats2013('test')\nprint(f\"Training Size = {len(t_dataset)}, Validation Size = {len(v_dataset)}, Test Size = {len(test_dataset)}\")\nprint(f\"Total Size = {sum([len(t_dataset), len(v_dataset), len(test_dataset)])}\")\ndataloader = DataLoader(dataset=t_dataset, batch_size=4, shuffle=True) # pin_memory=True, num_workers=8\n\nfor imgs, masks in dataloader:\n    print(imgs.shape, imgs.dtype, imgs.min(), imgs.max())\n    print(masks.shape, masks.dtype, masks.min(), masks.max())\n    break     \n\nfig, axes = plt.subplots(4,5, figsize=(20,16))\nfor b_n in range(4):\n    for i in range(4):\n        axes[b_n][i].imshow(imgs[b_n][i], cmap='gray')\n    axes[b_n][4].imshow(masks[b_n], cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:10.74841Z","iopub.execute_input":"2024-11-16T10:03:10.749333Z","iopub.status.idle":"2024-11-16T10:03:14.469853Z","shell.execute_reply.started":"2024-11-16T10:03:10.749286Z","shell.execute_reply":"2024-11-16T10:03:14.468836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_img, mask = imgs[2].numpy(), masks[2].numpy()\n# print(test_img.shape, test_img[3].min(), test_img[3].max())\n# # t_test_img = v2.ElasticTransform(alpha=5.0,sigma=10.0)(imgs[2])\n# t_test_img = elasticdeform.deform_random_grid([*test_img, mask], sigma=15, points=3, mode='constant', order=[1]*4+[0])\n# # plt.imshow(t_test_img)\n# # print(t_test_img.shape, t_test_img.min(), t_test_img.max())\n# print(t_test_img[3].min(), t_test_img[3].max())\n# print(t_test_img[4].min(), t_test_img[4].max())\n# fig, axes = plt.subplots(1,5, figsize=(20,16))\n# for i in range(4):\n#     axes[i].imshow(t_test_img[i], cmap='gray')\n# axes[4].imshow(t_test_img[4], cmap='gray')\n\n# all_datasets = []\n# for transform in transforms:\n#     all_datasets.append(Brats2013('train', transform=transform))\n\n# augmented_dataset = ConcatDataset([t_dataset, *all_datasets])\n# print(len(augmented_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:14.471422Z","iopub.execute_input":"2024-11-16T10:03:14.471747Z","iopub.status.idle":"2024-11-16T10:03:14.476412Z","shell.execute_reply.started":"2024-11-16T10:03:14.471713Z","shell.execute_reply":"2024-11-16T10:03:14.475423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"class InitWeights_He(object):\n    def __init__(self, neg_slope=1e-2):\n        self.neg_slope = neg_slope\n\n    def __call__(self, module):\n        if isinstance(module, nn.Conv3d) or isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d) or isinstance(module, nn.ConvTranspose3d):\n            module.weight = nn.init.kaiming_normal_(\n                module.weight, a=self.neg_slope)\n            if module.bias is not None:\n                module.bias = nn.init.constant_(module.bias, 0)\n                \nclass VGGBlock(torch.nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels, dropout_p=0.2):\n        super().__init__()\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout_p)\n        \n        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(middle_channels)\n        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        # out = self.dropout(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        return out\n    \nclass UNetPP_Xtra(torch.nn.Module):\n    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n        super().__init__()\n\n        self.weightInitializer = InitWeights_He()\n\n        \n        nb_filter = [32, 64, 128, 256, 512]\n\n        self.deep_supervision = deep_supervision\n\n        self.pool = nn.MaxPool2d(2, 2)\n        self.up = nn.Upsample(\n            scale_factor=2, mode='bicubic', align_corners=True)\n        \n        self.down = nn.functional.interpolate#(scale_factor=2, mode='bicubic')\n        self.d_conv0_0_1 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])\n        self.d_conv0_0_2 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])\n        self.d_conv0_0_3 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])\n        self.d_conv0_0_4 = VGGBlock(nb_filter[0], nb_filter[0], nb_filter[0])\n        \n        self.d_conv1_0_2 = VGGBlock(nb_filter[1], nb_filter[1], nb_filter[1])\n        self.d_conv1_0_3 = VGGBlock(nb_filter[1], nb_filter[1], nb_filter[1])\n        self.d_conv1_0_4 = VGGBlock(nb_filter[1], nb_filter[1], nb_filter[1])\n\n        self.d_conv2_0_3 = VGGBlock(nb_filter[2], nb_filter[2], nb_filter[2])\n        self.d_conv2_0_4 = VGGBlock(nb_filter[2], nb_filter[2], nb_filter[2])\n        \n        self.d_conv3_0_4 = VGGBlock(nb_filter[3], nb_filter[3], nb_filter[3])\n        \n        self.intermidiate_cnn = VGGBlock(nb_filter[4] + 32 + 64 + 128 + 256, nb_filter[4], nb_filter[4])\n        \n        \n        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n        self.conv2_0 = VGGBlock(nb_filter[1] + 32, nb_filter[2], nb_filter[2])\n        self.conv3_0 = VGGBlock(nb_filter[2] + 32 + 64, nb_filter[3], nb_filter[3])\n        self.conv4_0 = VGGBlock(nb_filter[3] + 32 + 64 + 128, nb_filter[4], nb_filter[4])\n        \n\n        self.conv0_1 = VGGBlock(\n            nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_1 = VGGBlock(\n            nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_1 = VGGBlock(\n            nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n        self.conv3_1 = VGGBlock(\n            nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n\n        self.conv0_2 = VGGBlock(\n            nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_2 = VGGBlock(\n            nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n        self.conv2_2 = VGGBlock(\n            nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n\n        self.conv0_3 = VGGBlock(\n            nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n        self.conv1_3 = VGGBlock(\n            nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n\n        self.conv0_4 = VGGBlock(\n            nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n\n        if self.deep_supervision:\n            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n        else:\n            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n            \n        self.apply(self.weightInitializer)\n\n    def forward(self, input):\n        x0_0 = self.conv0_0(input)\n        \n        x0_0_1 = self.d_conv0_0_1(self.down(x0_0, scale_factor=1/2, mode='bicubic'))\n        x0_0_2 = self.d_conv0_0_2(self.down(x0_0, scale_factor=1/4, mode='bicubic'))\n        x0_0_3 = self.d_conv0_0_3(self.down(x0_0, scale_factor=1/8, mode='bicubic'))\n        x0_0_4 = self.d_conv0_0_4(self.down(x0_0, scale_factor=1/16, mode='bicubic'))\n        \n        \n        x1_0 = self.conv1_0(self.pool(x0_0))\n        \n        x1_0_2 = self.d_conv1_0_2(self.down(x1_0, scale_factor=1/2, mode='bicubic'))\n        x1_0_3 = self.d_conv1_0_3(self.down(x1_0, scale_factor=1/4, mode='bicubic'))\n        x1_0_4 = self.d_conv1_0_4(self.down(x1_0, scale_factor=1/8, mode='bicubic'))\n        \n        \n        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n\n        # print(x1_0.shape)\n\n        x2_0 = self.conv2_0(self.pool(torch.cat([x1_0, x0_0_1], 1)))\n        \n        x2_0_3 = self.d_conv2_0_3(self.down(x2_0, scale_factor=1/2, mode='bicubic'))\n        x2_0_4 = self.d_conv2_0_4(self.down(x2_0, scale_factor=1/4, mode='bicubic'))\n\n        \n        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n\n        # print(x2_0.shape)\n        \n        x3_0 = self.conv3_0(self.pool(torch.cat([x2_0, x0_0_2, x1_0_2], 1)))\n        \n        x3_0_4 = self.d_conv3_0_4(self.down(x3_0, scale_factor=1/2, mode='bicubic'))\n        \n        \n        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n\n        # print(x3_0.shape)\n        \n        x4_0 = self.conv4_0(self.pool(torch.cat([x3_0, x0_0_3, x1_0_3, x2_0_3], 1)))\n        \n        # print(x4_0.shape, torch.cat([x4_0, x0_0_4, x1_0_4, x2_0_4, x3_0_4], 1).shape)\n        \n        x4_0 = self.intermidiate_cnn(torch.cat([x4_0, x0_0_4, x1_0_4, x2_0_4, x3_0_4], 1))\n        \n        # print(x4_0.shape)\n        \n        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n        x0_4 = self.conv0_4(\n            torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n\n        \n        \n        if self.deep_supervision:\n            output1 = self.final1(x0_1)\n            output2 = self.final2(x0_2)\n            output3 = self.final3(x0_3)\n            output4 = self.final4(x0_4)\n            return [output1, output2, output3, output4]\n\n        else:\n            output = self.final(x0_4)\n            return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:14.477951Z","iopub.execute_input":"2024-11-16T10:03:14.478278Z","iopub.status.idle":"2024-11-16T10:03:14.522162Z","shell.execute_reply.started":"2024-11-16T10:03:14.478234Z","shell.execute_reply":"2024-11-16T10:03:14.520756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install torchsummary \n# from torchsummary import summary\n# unet = UNetPP(1, 4)\n# # unet = Unet(1)\n# summary(unet, input_size=(4, 256, 256))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:14.523659Z","iopub.execute_input":"2024-11-16T10:03:14.524788Z","iopub.status.idle":"2024-11-16T10:03:14.534477Z","shell.execute_reply.started":"2024-11-16T10:03:14.524739Z","shell.execute_reply":"2024-11-16T10:03:14.533652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pseudo_data = torch.randn((2, 4, 256, 256))\n# unet = UNetPP_Xtra(1, 4)\nunet = UNetPP(1, 4)\n# unet = Unet(1)\nunet(pseudo_data).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:14.535583Z","iopub.execute_input":"2024-11-16T10:03:14.535941Z","iopub.status.idle":"2024-11-16T10:03:16.122276Z","shell.execute_reply.started":"2024-11-16T10:03:14.535888Z","shell.execute_reply":"2024-11-16T10:03:16.121239Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hyper params","metadata":{}},{"cell_type":"code","source":"max_epochs = 100\nbatch_size = 18 # change accordingly\nlr = 2e-4\nnum_workers = 4\npin_memory = True\n\nmodel_path = os.path.join(train_log_path, 'unetpp.pth')\n\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = True\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nmodel = UNetPP_Xtra(1,4)\n# model = UNetPP(1, 4)\n# model = Unet(1)\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n\n\ntransforms =[['h_flip'], ['v_flip'], ['rotate'], ['crop'], ['elastic_5'], ['brightness'], ['rotate', 'crop', 'elastic_5', 'brightness']]\ntrain_dataset = Brats2013('train')\nall_datasets = []\nfor transform in transforms:\n    all_datasets.append(Brats2013('train', transform=transform))\ntrain_dataset = ConcatDataset([train_dataset, *all_datasets])\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=pin_memory, num_workers=num_workers)\n\nval_dataset = Brats2013('val')\nval_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, pin_memory=pin_memory, num_workers=num_workers)\ntest_dataset = Brats2013('test')\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, pin_memory=pin_memory, num_workers=num_workers)\n\n\nprint(len(train_dataset), len(val_dataset), len(test_dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:16.123563Z","iopub.execute_input":"2024-11-16T10:03:16.123943Z","iopub.status.idle":"2024-11-16T10:03:16.353485Z","shell.execute_reply.started":"2024-11-16T10:03:16.123904Z","shell.execute_reply":"2024-11-16T10:03:16.352442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader):\n    with torch.no_grad():\n        batch_loss, batch_scores = [], []\n        \n        for batch_data in dataloader:\n            c_bs = batch_data[0].shape[0]\n            \n            X, Y = batch_data[0].to(device), batch_data[1].to(device) \n            \n            Y_ = model(X)\n            Y_, Y = Y_.squeeze(), Y.squeeze()\n            loss = loss_fun(Y_, Y)\n            batch_loss += [loss.cpu().item()]\n            \n            Y_copy = sigmoid_helper(Y_.detach().cpu()).numpy()\n            Y_copy = (Y_copy>=0.5).reshape(*Y_copy.shape).astype(np.uint8)\n            scores = iou_dice(Y_copy, Y.detach().cpu().numpy())\n            if type(scores) == float:\n                scores = [0.0, 0.0]\n            batch_scores += [[scores[0], scores[1]]] \n        \n    return sum(batch_loss)/len(batch_loss),  np.array(batch_scores).mean(0)\n\n    \n\n# def error_acc_plot(train_loss, val_loss, train_acc, val_acc):\n#     plt.figure(figsize=(15,5))\n#     plt.subplot(1,2,1)\n#     plt.plot(train_loss)\n#     plt.plot(val_loss)\n#     plt.xlabel(\"Epochs\")\n#     plt.ylabel(\"Loss\")\n#     plt.legend([\"Train\", \"Validation\"])\n#     plt.subplot(1,2,2)\n#     plt.plot(train_acc)\n#     plt.plot(val_acc)\n#     plt.xlabel(\"Epochs\")\n#     plt.ylabel(\"ACC\")\n#     plt.legend([\"Train\", \"Validation\"])\n#     plt.show()\n\n# def get_predictions(model, dataloader):\n#     preds = torch.tensor([])\n#     scores = []\n#     with torch.no_grad():\n#         for data in dataloader:\n#             X, Y = data[0].to(device), data[1]            \n#             Y_ = model(X).squeeze().detach().cpu()\n#             preds = torch.concat((preds,Y_), dim=0)\n#             # preds.append(Y_.detach().cpu.numpy())\n\n#             dice = compute_dice(F.sigmoid(Y_), Y)\n#             iou = compute_iou(F.sigmoid(Y_), Y)\n            \n#             scores.append([iou, dice])\n            \n#     return preds, np.array(scores).mean(0) \n    \ndef dice_loss(pred, target):\n    p_shape = pred.shape\n    mean_val = p_shape[0]*p_shape[1] # bs*class\n    \n    pred = pred\n    \n    pred, target = pred.flatten(), target.flatten()\n    smooth = 1e-8\n    intersection = (pred * target).sum()\n    union = (pred+target).sum()\n    dice_coefficient = (2*intersection + smooth) /  (union + smooth)\n    dice_coefficient = dice_coefficient/mean_val\n    dice_loss = 1-dice_coefficient\n    return dice_loss\n\n\ndef detect_edges(gray_img):\n    gray_img = gray_img\n    sobel_x = torch.tensor([[2,2,4,2,2], [1,1,2,1,1], [0,0,0,0,0], [-1,-1,-2,-1,-1], [-2,-2,-4,-2,-2]], dtype=torch.float32).view(1, 1, 5, 5).to(device)\n    sobel_y = torch.tensor([[2,1,0,-1,-2], [2,1,0,-1,-2], [4,2,0,-2,-4], [2,1,0,-1,-2], [2,1,0,-1,-2]], dtype=torch.float32).view(1, 1, 5, 5).to(device)\n    edge_x = F.conv2d(gray_img, sobel_x, padding=2)\n    edge_y = F.conv2d(gray_img, sobel_y, padding=2)\n    edge_magnitude = torch.sqrt(edge_x**2 + edge_y**2).squeeze(0)\n    return edge_magnitude/edge_magnitude.max()\n    \ndef edge_loss(pred, target):\n    pred, target = pred.unsqueeze(1).float(), target.unsqueeze(1).float()\n    edge_mask =  detect_edges(target)\n    weighted_loss = edge_mask*F.l1_loss(pred, target, reduction='none')\n    loss_edge = weighted_loss.mean()\n    return loss_edge\n\nsoftmax_helper = lambda x: F.softmax(x, 1)\nsigmoid_helper = lambda x: F.sigmoid(x)\n# ce = torch.nn.CrossEntropyLoss()\nbce = torch.nn.BCEWithLogitsLoss()\n\n# sigmoid_focal_loss(pred, target, reduction='mean')\n# sdl = SoftDiceLoss(apply_nonlin=sigmoid_helper, batch_dice=True, do_bg=True)\nsdl = SoftDiceLossSquared(apply_nonlin=softmax_helper, batch_dice=True, do_bg=True)\n\n# def loss_fun(Y_, Y):\n#     # dl = sdl(Y_, Y)\n#     _, Y = Y.max(1)\n#     cl = ce(Y_, Y) \n#     # return cl + dl\n#     return cl\n\ndef loss_fun(Y_, Y):\n    dl = sdl(Y_, Y)\n    # _, Y = Y.max(1)\n    # cl = ce(Y_, Y) \n    # return cl + dl\n    # print(Y.min(), Y.max(), Y_.min(), Y_.max())\n    bcl = bce(Y_.float(), Y.float())\n    loss_edge = edge_loss(Y_, Y)\n    return bcl + dl + loss_edge\n\n# def loss_fun(Y_, Y):\n#     # dl = sdl(Y_, Y)\n#     sfl = sigmoid_focal_loss(Y_.float(), Y.float(), reduction='mean')\n#     return sfl #+ 0.7 * dl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:16.356956Z","iopub.execute_input":"2024-11-16T10:03:16.357297Z","iopub.status.idle":"2024-11-16T10:03:16.378405Z","shell.execute_reply.started":"2024-11-16T10:03:16.357264Z","shell.execute_reply":"2024-11-16T10:03:16.377376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pbar = tqdm(range(max_epochs), desc='Epoch')\n# for epoch in pbar:\n\ntrain_loss, train_scores = [], []\nval_loss, val_scores = [], []\nprev_l, pat, j = 99, 7, 0 # 999\nfor epoch in range(max_epochs):\n    # train\n\n    batch_loss, batch_acc = [], []\n    batch_scores = []\n\n\n    pbar_batch = tqdm(train_dataloader, desc=f'Epoch {epoch}', leave=False)\n    for data in pbar_batch:\n    # for data in tqdm(train_dataloader):\n        c_bs = data[0].shape[0]\n        \n        X, Y = data[0].to(device), data[1].to(device) \n        \n        optimizer.zero_grad()\n        Y_ = model(X)\n        Y_, Y = Y_.squeeze(), Y.squeeze()\n        loss = loss_fun(Y_, Y)   \n        loss.backward()\n        optimizer.step()\n        \n        batch_loss += [loss.cpu().item()]\n        # iou, dice\n        # scores = iou_dice(Y_.detach().cpu().numpy(), Ycopy.detach().cpu().numpy())\n        Y_copy = sigmoid_helper(Y_.detach().cpu()).numpy()\n        Y_copy = (Y_copy>=0.5).reshape(*Y_copy.shape).astype(np.uint8)\n        scores = iou_dice(Y_copy, Y.detach().cpu().numpy())\n        if type(scores) == float:\n            scores = [0.0, 0.0]\n        batch_scores += [[scores[0], scores[1]]] \n         \n        pbar_batch.set_postfix({'b_loss':batch_loss[-1], 'iou':batch_scores[-1][0], 'dice':batch_scores[-1][1]})\n    \n    train_loss.append(sum(batch_loss)/len(batch_loss))\n    # print(batch_scores)\n    batch_scores = np.array(batch_scores).mean(0)\n    train_scores.append([batch_scores[0], batch_scores[1]])\n\n    # checking\n    b_n = random.randint(0, min(batch_size, c_bs)-1)\n    mix_img = X[b_n].detach().cpu() * 255\n    mix_img = np.concatenate((mix_img[0], mix_img[1], mix_img[2], mix_img[3],Y[b_n].detach().cpu()*255, Y_[b_n].detach().cpu()*255), axis=1)\n    cv2.imwrite(os.path.join(train_log_path, f'img_{epoch+1}.png'), mix_img)\n\n    \n        \n    # val\n    model.eval()\n    l, s = evaluate(model, val_dataloader)\n    val_loss.append(l)\n    val_scores.append(s)\n    print(f\"Epoch {epoch+1}: => t_loss={train_loss[-1]:2.4f}, t_iou={train_scores[-1][0]:2.4f}, t_dice={train_scores[-1][1]:2.4f}, v_loss={val_loss[-1]:2.4f}, v_iou={val_scores[-1][0]:2.4f}, v_dice={val_scores[-1][1]:2.4f}\")\n    \n    if l < prev_l:\n        prev_l = l\n        torch.save(model, model_path)\n        j=0\n\n    # if s[1] > prev_l:\n    #     prev_l = s[1]\n    #     torch.save(model, model_path)\n    #     j=0\n    else:\n        j += 1\n        if j > pat:\n            print(\"Early Stopping\")\n            break\n    \n    model.train()\n\n    \ntrain_losses, val_losses = np.array(train_loss), np.array(val_loss)\n# saving losses\nwith open(f'{train_log_path}/losses.pkl', 'wb') as f:\n    pickle.dump({'train_losses':train_losses, 'val_losses':val_losses}, f)\n\n# error_acc_plot(train_loss, val_loss, train_acc, val_acc)\nplt.plot(train_losses)\nplt.plot(val_losses)\nplt.legend(['Train', 'Val'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:03:16.379693Z","iopub.execute_input":"2024-11-16T10:03:16.380096Z","iopub.status.idle":"2024-11-16T10:04:38.499488Z","shell.execute_reply.started":"2024-11-16T10:03:16.380048Z","shell.execute_reply":"2024-11-16T10:04:38.498098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test dataset\n","metadata":{}},{"cell_type":"code","source":"pretrained_path =  model_path\nmodel = torch.load(pretrained_path)\nmodel.eval()\ntest_loss, scores = evaluate(model, val_dataloader)\ntest_loss, scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:04:41.87349Z","iopub.execute_input":"2024-11-16T10:04:41.873924Z","iopub.status.idle":"2024-11-16T10:04:46.032265Z","shell.execute_reply.started":"2024-11-16T10:04:41.873883Z","shell.execute_reply":"2024-11-16T10:04:46.031174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pretrained_path =  model_path\nmodel = torch.load(pretrained_path)\nmodel.eval()\ntest_loss, scores = evaluate(model, test_dataloader)\ntest_loss, scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T10:04:46.034157Z","iopub.execute_input":"2024-11-16T10:04:46.034501Z","iopub.status.idle":"2024-11-16T10:04:53.344946Z","shell.execute_reply.started":"2024-11-16T10:04:46.034467Z","shell.execute_reply":"2024-11-16T10:04:53.343848Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model loading","metadata":{}},{"cell_type":"code","source":"# pretrained_path =  '/kaggle/input/unetpp-sqloss/unetpp.pth'\n# model = torch.load(pretrained_path)\n# model.eval()\n\n# preds, scores = evaluate(model, test_dataloader)\n# scores","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}